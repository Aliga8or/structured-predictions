{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from vowpalwabbit import pyvw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = {}\n",
    "tag['CC'] = 1\n",
    "tag['CD'] = 2\n",
    "tag['DT'] = 3\n",
    "tag['EX'] = 3\n",
    "tag['FW'] = 4\n",
    "tag['IN'] = 5\n",
    "tag['JJ'] = 6\n",
    "tag['JJR'] = 6\n",
    "tag['JJS'] = 6\n",
    "tag['MD'] = 7\n",
    "tag['NN'] = 8\n",
    "tag['NNP'] = 8\n",
    "tag['NNPS'] = 8\n",
    "tag['NNS'] = 8\n",
    "tag['PDT'] = 3\n",
    "tag['POS'] = 11\n",
    "tag['PRP'] = 9\n",
    "tag['PRP$'] = 9\n",
    "tag['RB'] = 10\n",
    "tag['RBR'] = 10\n",
    "tag['RBS'] = 10\n",
    "tag['RP'] = 11\n",
    "tag['SYM'] = 12\n",
    "tag['TO'] = 11\n",
    "tag['UH'] = 13\n",
    "tag['VB'] = 14\n",
    "tag['VBD'] = 14\n",
    "tag['VBG'] = 14\n",
    "tag['VBN'] = 14\n",
    "tag['VBP'] = 14\n",
    "tag['VBZ'] = 14\n",
    "tag['WDT'] = 3\n",
    "tag['WP'] = 9\n",
    "tag['WP$'] = 9\n",
    "tag['WRB'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "punc = ['#', '$',\"''\",'(',')',',','.',':',\"``\"]\n",
    "sentence = []\n",
    "sentences = []\n",
    "pos_tags = set([])\n",
    "file = open('train.txt', 'r') \n",
    "for line in file:\n",
    "    if line == '\\n': \n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    parts = line.split()\n",
    "    if parts[1] in punc:\n",
    "        continue\n",
    "    pos_tags.add(parts[1])\n",
    "    tup = (tag[parts[1]],parts[0])\n",
    "    sentence.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Confidence\n"
     ]
    }
   ],
   "source": [
    "print (sentences[0][0][0])\n",
    "print (sentences[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevent\n",
      "14\n",
      "pressure\n",
      "8\n",
      "prepared\n",
      "14\n",
      "preoccupied\n",
      "14\n",
      "predict\n",
      "14\n",
      "previously\n",
      "10\n",
      "pressure\n",
      "8\n",
      "president\n",
      "8\n",
      "present\n",
      "6\n",
      "previous\n",
      "6\n",
      "previous\n",
      "6\n",
      "previous\n",
      "6\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "pressure\n",
      "14\n",
      "president\n",
      "8\n",
      "pretext\n",
      "8\n",
      "present\n",
      "14\n",
      "presidential\n",
      "6\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "previous-month\n",
      "6\n",
      "president\n",
      "8\n",
      "previous\n",
      "6\n",
      "previous\n",
      "6\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "previous\n",
      "6\n",
      "pretax\n",
      "6\n",
      "pretax\n",
      "6\n",
      "prefer\n",
      "14\n",
      "president\n",
      "8\n",
      "pressure\n",
      "8\n",
      "pressure\n",
      "8\n",
      "predicted\n",
      "14\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "previously\n",
      "10\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "presidents\n",
      "8\n",
      "preparing\n",
      "14\n",
      "pressing\n",
      "14\n",
      "pressure\n",
      "8\n",
      "previously\n",
      "10\n",
      "press\n",
      "14\n",
      "pressure\n",
      "8\n",
      "prepay\n",
      "14\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "presidency\n",
      "8\n",
      "prepared\n",
      "14\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "pressed\n",
      "14\n",
      "prepared\n",
      "14\n",
      "pressure\n",
      "8\n",
      "president\n",
      "8\n",
      "presented\n",
      "14\n",
      "presentations\n",
      "8\n",
      "presented\n",
      "14\n",
      "previously\n",
      "10\n",
      "previously\n",
      "10\n",
      "president\n",
      "8\n",
      "president\n",
      "8\n",
      "precipitated\n",
      "14\n",
      "present\n",
      "6\n",
      "preferring\n",
      "14\n",
      "precious\n",
      "6\n",
      "precious\n",
      "6\n",
      "precious\n",
      "6\n",
      "president\n",
      "8\n",
      "premium\n",
      "8\n",
      "previously\n",
      "10\n",
      "president\n",
      "8\n",
      "prevalent\n",
      "6\n",
      "president\n",
      "8\n",
      "predicts\n",
      "14\n",
      "president\n",
      "8\n",
      "predict\n",
      "14\n",
      "pressures\n",
      "8\n",
      "previously\n",
      "10\n",
      "prepare\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for aSent in sentences[:1000]:\n",
    "    for aTuple in aSent:\n",
    "        pos,word = aTuple\n",
    "        if word.lower().startswith(\"pre\"):\n",
    "            print (word)\n",
    "            print (pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_test = []\n",
    "sentences_test = []\n",
    "pos_tags_test = set([])\n",
    "file = open('test.txt', 'r') \n",
    "for line in file:\n",
    "    if line == '\\n': \n",
    "        sentences_test.append(sentence_test)\n",
    "        sentence_test = []\n",
    "        continue\n",
    "    parts = line.split()\n",
    "    if parts[1] in punc:\n",
    "        continue\n",
    "    pos_tags_test.add(parts[1])\n",
    "    tup = (tag[parts[1]],parts[0])\n",
    "    sentence_test.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        # you must must must initialize the parent class\n",
    "        # this will automatically store self.sch <- sch, self.vw <- vw\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        \n",
    "        # set whatever options you want\n",
    "        sch.set_options( sch.AUTO_HAMMING_LOSS | sch.AUTO_CONDITION_FEATURES )\n",
    "\n",
    "    def _run(self, sentence):   # it's called _run to remind you that you shouldn't call it directly!\n",
    "        output = []\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            # use \"with...as...\" to guarantee that the example is finished properly\n",
    "            with self.vw.example({'w': [word]}) as ex:\n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'), (n-1, 'q')])\n",
    "                output.append(pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler2(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_HAMMING_LOSS)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        #loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            prevPred = output[n-1] if n > 0 else '<s>'\n",
    "            prev_n_2 = output[n-2] if n > 1 else '<s>'\n",
    "            posnew, prevWord = sentence[n-1] if n> 0 else ('<s>','<s>')\n",
    "            with self.vw.example({'w': [word],'p': [prevPred], 'r':[prevWord]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n,'r')])\n",
    "                output.append(pred)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "#sequenceLabeler2 = vw.init_search_task(SequenceLabeler2)\n",
    "#sequenceLabeler2.learn(my_dataset)\n",
    "#print(sequenceLabeler2.predict( [(0,w) for w in \"the sandwich ate a monster\".split()] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler3(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            with self.vw.example({'w': [word]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n-1,'q')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss += wt_err[pos]            \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLabeler4(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            with self.vw.example({'w': [word]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n-1,'q')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss += wt[pos]            \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLabeler5(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            with self.vw.example({'w': [word]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n-1,'q')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss = 1           \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratnaparkhi 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLabelerRp1(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        #sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "        sch.set_options(sch.AUTO_HAMMING_LOSS)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            prevPred = output[n-1] if n > 0 else '<s>'\n",
    "            #prev_n_2 = output[n-2] if n > 1 else '<s>'\n",
    "            #posnew, prevWord = sentence[n-1] if n> 0 else ('<s>','<s>')\n",
    "            #with self.vw.example({'w': [word],'p': [prevPred], 'r':[prevWord]}) as ex:\n",
    "            \n",
    "            # ing feature\n",
    "            f1 = 0\n",
    "            #if word.endswith(\"ing\") and (pos == 14):\n",
    "            if word.lower().endswith(\"ing\"):\n",
    "                f1 = 1\n",
    "            \n",
    "            # pre feature\n",
    "            f2 = 0\n",
    "            #if word.startswith(\"pre\") and (pos == 8):\n",
    "            if word.lower().startswith(\"pre\"):\n",
    "                f2 = 1\n",
    "            \n",
    "            with self.vw.example({'w': [word], 'p': [prevPred], 'q': [f1], 'r': [f2]}) as ex:\n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n,'q'),(n,'r')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss = 1           \n",
    "        #self.sch.loss(loss)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "#sequenceLabeler2 = vw.init_search_task(SequenceLabeler2)\n",
    "#sequenceLabeler2.learn(my_dataset)\n",
    "#print(sequenceLabeler2.predict( [(0,w) for w in \"the sandwich ate a monster\".split()] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratnaparkhi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLabelerRp2(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        #sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "        sch.set_options(sch.AUTO_HAMMING_LOSS)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            prevPred = output[n-1] if n > 0 else '<s>'\n",
    "            #prev_n_2 = output[n-2] if n > 1 else '<s>'\n",
    "            posprev, prevWord = sentence[n-1] if n> 0 else ('<s>','<s>')\n",
    "            posnext, nextWord = sentence[n+1] if (n+1)< len(sentence) else ('<s>','<s>')\n",
    "            #with self.vw.example({'w': [word],'p': [prevPred], 'r':[prevWord]}) as ex:\n",
    "            \n",
    "            # ing feature\n",
    "            f1 = 0\n",
    "            #if word.endswith(\"ing\") and (pos == 14):\n",
    "            if word.lower().endswith(\"ing\"):\n",
    "                f1 = 1\n",
    "            \n",
    "            # pre feature\n",
    "            f2 = 0\n",
    "            #if word.startswith(\"pre\") and (pos == 8):\n",
    "            if word.lower().startswith(\"pre\"):\n",
    "                f2 = 1\n",
    "            \n",
    "            # the @ n-1 feature\n",
    "            f3 = 0\n",
    "            #if word.startswith(\"pre\") and (pos == 8):\n",
    "            if prevWord.lower() == \"the\":\n",
    "                f3 = 1\n",
    "            \n",
    "            # the @ n+1 feature\n",
    "            f4 = 0\n",
    "            #if word.startswith(\"pre\") and (pos == 8):\n",
    "            if nextWord.lower() == \"the\":\n",
    "                f4 = 1\n",
    "            \n",
    "            with self.vw.example({'w': [word], 'p': [prevPred], 'q': [f3], 'r': [f4]}) as ex:\n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n,'q'),(n,'r')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss = 1           \n",
    "        #self.sch.loss(loss)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "#sequenceLabeler2 = vw.init_search_task(SequenceLabeler2)\n",
    "#sequenceLabeler2.learn(my_dataset)\n",
    "#print(sequenceLabeler2.predict( [(0,w) for w in \"the sandwich ate a monster\".split()] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLabelerGold(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        #sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "        #sch.set_options(sch.AUTO_HAMMING_LOSS)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            prevPred = output[n-1] if n > 0 else '<s>'\n",
    "            prev_n_2 = output[n-2] if n > 1 else '<s>'\n",
    "            posnew, prevWord = sentence[n-1] if n> 0 else ('<s>','<s>')\n",
    "            with self.vw.example({'w': [word],'p': [prevPred], 'r':[prevWord]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n,'r')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss = 1           \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "#sequenceLabeler2 = vw.init_search_task(SequenceLabeler2)\n",
    "#sequenceLabeler2.learn(my_dataset)\n",
    "#print(sequenceLabeler2.predict( [(0,w) for w in \"the sandwich ate a monster\".split()] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loss():\n",
    "    print(\"Calculating training loss...\")\n",
    "    global tag_count\n",
    "    global tag_error\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    loss_t=[]\n",
    "    s=0\n",
    "    for sen in sentences[:1000]:\n",
    "        s+=1\n",
    "        temp=[]\n",
    "        for w in sen:\n",
    "            temp.append((1,w[1]))\n",
    "        out = sequenceLabeler.predict(temp)\n",
    "        #print(out)\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in out:        \n",
    "            if sen[c][0] in tag_count:\n",
    "                tag_count[sen[c][0]] += 1\n",
    "            else:\n",
    "                tag_count[sen[c][0]] = float(1)\n",
    "                tag_error[sen[c][0]] = float(0)\n",
    "\n",
    "            if i != sen[c][0]:\n",
    "                loss+=1\n",
    "                tag_error[sen[c][0]] += 1\n",
    "                #print (\"Predicted value at \",c,\" is \",i)\n",
    "                #print (sentences[0][c])\n",
    "            c+=1\n",
    "        loss_t.append(loss/float(c))\n",
    "\n",
    "    print (\"Training Loss:\")\n",
    "    print (sum(loss_t) / float(len(loss_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss():\n",
    "    print(\"Calculating test loss...\")\n",
    "    global tag_count\n",
    "    global tag_error\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    loss_t=[]\n",
    "    s=0\n",
    "    for sen in sentences_test:\n",
    "        s+=1\n",
    "        temp=[]\n",
    "        for w in sen:\n",
    "            temp.append((1,w[1]))\n",
    "        out = sequenceLabeler.predict(temp)\n",
    "        #print(out)\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in out:        \n",
    "            if sen[c][0] in tag_count:\n",
    "                tag_count[sen[c][0]] += 1\n",
    "            else:\n",
    "                tag_count[sen[c][0]] = float(1)\n",
    "                tag_error[sen[c][0]] = float(0)\n",
    "\n",
    "            if i != sen[c][0]:\n",
    "                loss+=1\n",
    "                tag_error[sen[c][0]] += 1\n",
    "                #print (\"Predicted value at \",c,\" is \",i)\n",
    "                #print (sentences[0][c])\n",
    "            c+=1\n",
    "        loss_t.append(loss/float(c))\n",
    "\n",
    "    print (\"Test Loss:\")\n",
    "    print (sum(loss_t) / float(len(loss_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def updateWeights():\n",
    "    print(\"Updating weights...\")\n",
    "    tag_loss = {}\n",
    "    sum_err=0\n",
    "    for t in tag_count:\n",
    "        tag_loss[t] = tag_error[t]/tag_count[t]\n",
    "        sum_err+=tag_error[t]\n",
    "        \n",
    "    sorted_loss = sorted(tag_loss.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    for tp in sorted_loss:\n",
    "            print( tp[0], \" = \", tag_error[tp[0]], \"/\", tag_count[tp[0]], \" = \", tp[1] )\n",
    "            wt_err[tp[0]]=tp[1]*(tag_error[tp[0]]/sum_err)\n",
    "            \n",
    "    avg_err=sum(wt_err)/14.0\n",
    "    wt_err[:]=[1+(x - avg_err) for x in wt_err]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = pyvw.vw(\"--search 14 --audit --quiet --search_task hook --ring_size 1024 -f pos_tagger.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLabeler = vw.init_search_task(SequenceLabelerRp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_err=[1]*15\n",
    "tag_count = {}\n",
    "tag_error = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0472563791476\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.136943661398\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0442743932739\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.135636213701\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0448799255814\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.136534322135\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0447805006025\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.136985796514\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0449880803822\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.137206436963\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    #updateWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0449880803822\n",
      "Updating weights...\n",
      "1  =  0.0 / 1150.0  =  0.0\n",
      "4  =  0.0 / 14.0  =  0.0\n",
      "7  =  0.0 / 470.0  =  0.0\n",
      "5  =  30.0 / 5174.0  =  0.00579822187862\n",
      "11  =  12.0 / 1612.0  =  0.00744416873449\n",
      "9  =  16.0 / 1170.0  =  0.0136752136752\n",
      "3  =  156.0 / 4380.0  =  0.0356164383562\n",
      "8  =  602.0 / 14766.0  =  0.0407693349587\n",
      "6  =  242.0 / 3430.0  =  0.0705539358601\n",
      "2  =  124.0 / 1742.0  =  0.0711825487945\n",
      "14  =  488.0 / 6340.0  =  0.0769716088328\n",
      "10  =  160.0 / 1566.0  =  0.102171136654\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.137206436963\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  70.0 / 5071.0  =  0.0138039834352\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1470.0 / 14612.0  =  0.10060224473\n",
      "14  =  1446.0 / 6232.0  =  0.232028241335\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1168.0 / 3243.0  =  0.360160345359\n",
      "2  =  722.0 / 1918.0  =  0.376433785193\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "train_loss()\n",
    "updateWeights()\n",
    "test_loss()\n",
    "updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = {}\n",
    "\n",
    "wt[1] = 1.0 \n",
    "wt[2] = 1.0\n",
    "wt[3] = 1.0\n",
    "wt[4] = 1.0\n",
    "wt[5] = 1.0\n",
    "wt[6] = 1.2\n",
    "wt[7] = 1.0\n",
    "wt[8] = 1.1\n",
    "wt[9] = 1.0\n",
    "wt[10] = 1.2\n",
    "wt[11] = 1.0\n",
    "wt[12] = 1.0\n",
    "wt[13] = 1.0\n",
    "wt[14] = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0509687903932\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.137398884444\n",
      "Updating weights...\n",
      "11  =  16.0 / 1624.0  =  0.00985221674877\n",
      "1  =  13.0 / 1214.0  =  0.0107084019769\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "5  =  88.0 / 5071.0  =  0.0173535791757\n",
      "3  =  174.0 / 4280.0  =  0.0406542056075\n",
      "9  =  60.0 / 1349.0  =  0.0444773906597\n",
      "8  =  1239.0 / 14612.0  =  0.0847933205584\n",
      "14  =  1451.0 / 6232.0  =  0.23283055199\n",
      "10  =  434.0 / 1567.0  =  0.276962348437\n",
      "6  =  1190.0 / 3243.0  =  0.366944187481\n",
      "2  =  789.0 / 1918.0  =  0.411366006257\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0447766393709\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.135841969592\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  72.0 / 5071.0  =  0.0141983829619\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  32.0 / 1349.0  =  0.0237212750185\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1378.0 / 14612.0  =  0.0943060498221\n",
      "14  =  1465.0 / 6232.0  =  0.235077021823\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1172.0 / 3243.0  =  0.3613937712\n",
      "2  =  725.0 / 1918.0  =  0.377997914494\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0449668456432\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.136211315114\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  70.0 / 5071.0  =  0.0138039834352\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1392.0 / 14612.0  =  0.0952641664385\n",
      "14  =  1473.0 / 6232.0  =  0.23636071887\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1170.0 / 3243.0  =  0.360777058279\n",
      "2  =  725.0 / 1918.0  =  0.377997914494\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0452751650361\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.136964142951\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  70.0 / 5071.0  =  0.0138039834352\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1390.0 / 14612.0  =  0.0951272926362\n",
      "14  =  1503.0 / 6232.0  =  0.241174582798\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  423.0 / 1567.0  =  0.269942565412\n",
      "6  =  1170.0 / 3243.0  =  0.360777058279\n",
      "2  =  725.0 / 1918.0  =  0.377997914494\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0453482780368\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.137200246243\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  70.0 / 5071.0  =  0.0138039834352\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1397.0 / 14612.0  =  0.0956063509444\n",
      "14  =  1507.0 / 6232.0  =  0.241816431322\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1169.0 / 3243.0  =  0.360468701819\n",
      "2  =  725.0 / 1918.0  =  0.377997914494\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static weight updates 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = {}\n",
    "\n",
    "wt[1] = 1.0 \n",
    "wt[2] = 1.0\n",
    "wt[3] = 1.0\n",
    "wt[4] = 1.0\n",
    "wt[5] = 1.0\n",
    "wt[6] = 1.4\n",
    "wt[7] = 1.0\n",
    "wt[8] = 1.25\n",
    "wt[9] = 1.0\n",
    "wt[10] = 1.4\n",
    "wt[11] = 1.0\n",
    "wt[12] = 1.0\n",
    "wt[13] = 1.0\n",
    "wt[14] = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0562226198542\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.138625882943\n",
      "Updating weights...\n",
      "11  =  16.0 / 1624.0  =  0.00985221674877\n",
      "1  =  13.0 / 1214.0  =  0.0107084019769\n",
      "5  =  99.0 / 5071.0  =  0.0195227765727\n",
      "7  =  18.0 / 470.0  =  0.0382978723404\n",
      "3  =  177.0 / 4280.0  =  0.0413551401869\n",
      "9  =  66.0 / 1349.0  =  0.0489251297257\n",
      "8  =  1189.0 / 14612.0  =  0.0813714754996\n",
      "14  =  1462.0 / 6232.0  =  0.23459563543\n",
      "10  =  444.0 / 1567.0  =  0.283343969368\n",
      "6  =  1204.0 / 3243.0  =  0.371261177922\n",
      "2  =  832.0 / 1918.0  =  0.433785192909\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0451226472155\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.135988618917\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  16.0 / 1624.0  =  0.00985221674877\n",
      "5  =  76.0 / 5071.0  =  0.0149871820154\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  35.0 / 1349.0  =  0.0259451445515\n",
      "3  =  174.0 / 4280.0  =  0.0406542056075\n",
      "8  =  1362.0 / 14612.0  =  0.0932110594032\n",
      "14  =  1451.0 / 6232.0  =  0.23283055199\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1172.0 / 3243.0  =  0.3613937712\n",
      "2  =  735.0 / 1918.0  =  0.383211678832\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0447638712148\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.136169438694\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  73.0 / 5071.0  =  0.0143955827253\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  31.0 / 1349.0  =  0.0229799851742\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1393.0 / 14612.0  =  0.0953326033397\n",
      "14  =  1470.0 / 6232.0  =  0.235879332478\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  418.0 / 1567.0  =  0.266751754946\n",
      "6  =  1170.0 / 3243.0  =  0.360777058279\n",
      "2  =  726.0 / 1918.0  =  0.378519290928\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0449357302559\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.1371354146\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  73.0 / 5071.0  =  0.0143955827253\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  31.0 / 1349.0  =  0.0229799851742\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1418.0 / 14612.0  =  0.0970435258691\n",
      "14  =  1487.0 / 6232.0  =  0.238607188703\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  423.0 / 1567.0  =  0.269942565412\n",
      "6  =  1169.0 / 3243.0  =  0.360468701819\n",
      "2  =  726.0 / 1918.0  =  0.378519290928\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0454547095019\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.137513144524\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  72.0 / 5071.0  =  0.0141983829619\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1418.0 / 14612.0  =  0.0970435258691\n",
      "14  =  1504.0 / 6232.0  =  0.241335044929\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1164.0 / 3243.0  =  0.358926919519\n",
      "2  =  726.0 / 1918.0  =  0.378519290928\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0/1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0479161243961\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.136344372717\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  21.0 / 1624.0  =  0.0129310344828\n",
      "5  =  94.0 / 5071.0  =  0.0185367777559\n",
      "7  =  9.0 / 470.0  =  0.0191489361702\n",
      "9  =  46.0 / 1349.0  =  0.0340993328391\n",
      "3  =  163.0 / 4280.0  =  0.0380841121495\n",
      "8  =  1377.0 / 14612.0  =  0.0942376129209\n",
      "14  =  1299.0 / 6232.0  =  0.208440308087\n",
      "10  =  444.0 / 1567.0  =  0.283343969368\n",
      "6  =  1242.0 / 3243.0  =  0.382978723404\n",
      "2  =  755.0 / 1918.0  =  0.393639207508\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0411543364836\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134548744193\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "5  =  82.0 / 5071.0  =  0.0161703805955\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  31.0 / 1349.0  =  0.0229799851742\n",
      "3  =  157.0 / 4280.0  =  0.0366822429907\n",
      "8  =  1474.0 / 14612.0  =  0.100875992335\n",
      "14  =  1304.0 / 6232.0  =  0.209242618742\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  425.0 / 1567.0  =  0.271218889598\n",
      "6  =  1178.0 / 3243.0  =  0.36324390996\n",
      "2  =  711.0 / 1918.0  =  0.370698644421\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0400279821859\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134363720347\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  29.0 / 1349.0  =  0.0214974054855\n",
      "5  =  118.0 / 5071.0  =  0.0232695720765\n",
      "3  =  124.0 / 4280.0  =  0.0289719626168\n",
      "8  =  1472.0 / 14612.0  =  0.100739118533\n",
      "14  =  1324.0 / 6232.0  =  0.212451861361\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1162.0 / 3243.0  =  0.358310206599\n",
      "2  =  714.0 / 1918.0  =  0.372262773723\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0385003586751\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134398907608\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  17.0 / 1624.0  =  0.0104679802956\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  29.0 / 1349.0  =  0.0214974054855\n",
      "5  =  128.0 / 5071.0  =  0.0252415697101\n",
      "3  =  113.0 / 4280.0  =  0.0264018691589\n",
      "8  =  1452.0 / 14612.0  =  0.0993703805092\n",
      "14  =  1367.0 / 6232.0  =  0.219351732991\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  424.0 / 1567.0  =  0.270580727505\n",
      "6  =  1146.0 / 3243.0  =  0.353376503238\n",
      "2  =  717.0 / 1918.0  =  0.373826903024\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0380638336721\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134177751904\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  17.0 / 1624.0  =  0.0104679802956\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  28.0 / 1349.0  =  0.0207561156412\n",
      "5  =  128.0 / 5071.0  =  0.0252415697101\n",
      "3  =  113.0 / 4280.0  =  0.0264018691589\n",
      "8  =  1463.0 / 14612.0  =  0.100123186422\n",
      "14  =  1366.0 / 6232.0  =  0.21919127086\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  423.0 / 1567.0  =  0.269942565412\n",
      "6  =  1149.0 / 3243.0  =  0.354301572618\n",
      "2  =  697.0 / 1918.0  =  0.363399374348\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0673703156967\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.102423956541\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  12.0 / 1214.0  =  0.00988467874794\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  90.0 / 5071.0  =  0.0177479787024\n",
      "9  =  26.0 / 1349.0  =  0.0192735359526\n",
      "3  =  115.0 / 4280.0  =  0.0268691588785\n",
      "8  =  953.0 / 14612.0  =  0.0652203668218\n",
      "14  =  904.0 / 6232.0  =  0.145057766367\n",
      "10  =  382.0 / 1567.0  =  0.243777919592\n",
      "2  =  586.0 / 1918.0  =  0.305526590198\n",
      "6  =  1068.0 / 3243.0  =  0.329324699352\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0494833066321\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.0986787942501\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  10.0 / 1214.0  =  0.00823723228995\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  23.0 / 1349.0  =  0.0170496664196\n",
      "5  =  96.0 / 5071.0  =  0.0189311772826\n",
      "3  =  95.0 / 4280.0  =  0.0221962616822\n",
      "8  =  1136.0 / 14612.0  =  0.0777443197372\n",
      "14  =  845.0 / 6232.0  =  0.135590500642\n",
      "10  =  346.0 / 1567.0  =  0.220804084237\n",
      "2  =  506.0 / 1918.0  =  0.263816475495\n",
      "6  =  941.0 / 3243.0  =  0.290163428924\n",
      "4  =  2.0 / 4.0  =  0.5\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.043128809374\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.098849852238\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  10.0 / 1214.0  =  0.00823723228995\n",
      "7  =  6.0 / 470.0  =  0.0127659574468\n",
      "9  =  19.0 / 1349.0  =  0.0140845070423\n",
      "5  =  99.0 / 5071.0  =  0.0195227765727\n",
      "3  =  84.0 / 4280.0  =  0.0196261682243\n",
      "8  =  1230.0 / 14612.0  =  0.0841773884479\n",
      "14  =  835.0 / 6232.0  =  0.133985879332\n",
      "10  =  332.0 / 1567.0  =  0.211869814933\n",
      "2  =  475.0 / 1918.0  =  0.247653806048\n",
      "6  =  918.0 / 3243.0  =  0.283071230342\n",
      "4  =  2.0 / 4.0  =  0.5\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0405809891148\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.0979423233973\n",
      "Updating weights...\n",
      "11  =  11.0 / 1624.0  =  0.00677339901478\n",
      "1  =  10.0 / 1214.0  =  0.00823723228995\n",
      "7  =  5.0 / 470.0  =  0.0106382978723\n",
      "9  =  19.0 / 1349.0  =  0.0140845070423\n",
      "5  =  79.0 / 5071.0  =  0.0155787813055\n",
      "3  =  81.0 / 4280.0  =  0.0189252336449\n",
      "8  =  1284.0 / 14612.0  =  0.0878729811114\n",
      "14  =  827.0 / 6232.0  =  0.132702182285\n",
      "10  =  324.0 / 1567.0  =  0.206764518188\n",
      "2  =  457.0 / 1918.0  =  0.23826903024\n",
      "6  =  902.0 / 3243.0  =  0.278137526981\n",
      "4  =  2.0 / 4.0  =  0.5\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0389182262607\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.0988534748149\n",
      "Updating weights...\n",
      "11  =  11.0 / 1624.0  =  0.00677339901478\n",
      "1  =  9.0 / 1214.0  =  0.00741350906096\n",
      "7  =  6.0 / 470.0  =  0.0127659574468\n",
      "9  =  18.0 / 1349.0  =  0.0133432171979\n",
      "5  =  82.0 / 5071.0  =  0.0161703805955\n",
      "3  =  80.0 / 4280.0  =  0.018691588785\n",
      "8  =  1333.0 / 14612.0  =  0.0912263892691\n",
      "14  =  829.0 / 6232.0  =  0.133023106547\n",
      "10  =  321.0 / 1567.0  =  0.204850031908\n",
      "2  =  449.0 / 1918.0  =  0.23409801877\n",
      "6  =  895.0 / 3243.0  =  0.275979031761\n",
      "4  =  2.0 / 4.0  =  0.5\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:5000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratnaparkhi oracle aided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0500827863288\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.139858832411\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  22.0 / 1624.0  =  0.0135467980296\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "5  =  97.0 / 5071.0  =  0.0191283770459\n",
      "9  =  49.0 / 1349.0  =  0.0363232023721\n",
      "3  =  162.0 / 4280.0  =  0.0378504672897\n",
      "8  =  1495.0 / 14612.0  =  0.10231316726\n",
      "14  =  1367.0 / 6232.0  =  0.219351732991\n",
      "10  =  436.0 / 1567.0  =  0.278238672623\n",
      "6  =  1231.0 / 3243.0  =  0.379586802344\n",
      "2  =  756.0 / 1918.0  =  0.394160583942\n",
      "4  =  4.0 / 4.0  =  1.0\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0426078653255\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134364919634\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  157.0 / 4280.0  =  0.0366822429907\n",
      "8  =  1395.0 / 14612.0  =  0.0954694771421\n",
      "14  =  1419.0 / 6232.0  =  0.2276957638\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  424.0 / 1567.0  =  0.270580727505\n",
      "6  =  1173.0 / 3243.0  =  0.36170212766\n",
      "2  =  714.0 / 1918.0  =  0.372262773723\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0422965731268\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134194591913\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  76.0 / 5071.0  =  0.0149871820154\n",
      "9  =  28.0 / 1349.0  =  0.0207561156412\n",
      "3  =  156.0 / 4280.0  =  0.0364485981308\n",
      "8  =  1384.0 / 14612.0  =  0.0947166712291\n",
      "14  =  1443.0 / 6232.0  =  0.231546854942\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  419.0 / 1567.0  =  0.267389917039\n",
      "6  =  1167.0 / 3243.0  =  0.359851988899\n",
      "2  =  713.0 / 1918.0  =  0.371741397289\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0424294495555\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134308425375\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  26.0 / 1349.0  =  0.0192735359526\n",
      "3  =  156.0 / 4280.0  =  0.0364485981308\n",
      "8  =  1370.0 / 14612.0  =  0.0937585546126\n",
      "14  =  1460.0 / 6232.0  =  0.234274711168\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1167.0 / 3243.0  =  0.359851988899\n",
      "2  =  715.0 / 1918.0  =  0.372784150156\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0423672097091\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.134182234184\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  26.0 / 1349.0  =  0.0192735359526\n",
      "3  =  154.0 / 4280.0  =  0.0359813084112\n",
      "8  =  1350.0 / 14612.0  =  0.0923898165891\n",
      "14  =  1472.0 / 6232.0  =  0.236200256739\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1171.0 / 3243.0  =  0.361085414739\n",
      "2  =  716.0 / 1918.0  =  0.37330552659\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratnaparkhi 1 w/o oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0482208012741\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.132987339159\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  22.0 / 1624.0  =  0.0135467980296\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "5  =  97.0 / 5071.0  =  0.0191283770459\n",
      "9  =  46.0 / 1349.0  =  0.0340993328391\n",
      "3  =  164.0 / 4280.0  =  0.0383177570093\n",
      "8  =  1514.0 / 14612.0  =  0.103613468382\n",
      "14  =  1026.0 / 6232.0  =  0.164634146341\n",
      "10  =  437.0 / 1567.0  =  0.278876834716\n",
      "6  =  1243.0 / 3243.0  =  0.383287079864\n",
      "2  =  751.0 / 1918.0  =  0.391553701773\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.041023989362\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.130220510074\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  28.0 / 1349.0  =  0.0207561156412\n",
      "3  =  157.0 / 4280.0  =  0.0366822429907\n",
      "8  =  1529.0 / 14612.0  =  0.1046400219\n",
      "14  =  1088.0 / 6232.0  =  0.17458279846\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  423.0 / 1567.0  =  0.269942565412\n",
      "6  =  1180.0 / 3243.0  =  0.36386062288\n",
      "2  =  713.0 / 1918.0  =  0.371741397289\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0398246270936\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.129787373284\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  76.0 / 5071.0  =  0.0149871820154\n",
      "9  =  27.0 / 1349.0  =  0.0200148257969\n",
      "3  =  156.0 / 4280.0  =  0.0364485981308\n",
      "8  =  1517.0 / 14612.0  =  0.103818779086\n",
      "14  =  1106.0 / 6232.0  =  0.177471116816\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1169.0 / 3243.0  =  0.360468701819\n",
      "2  =  713.0 / 1918.0  =  0.371741397289\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0397385342406\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.129435451239\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  26.0 / 1349.0  =  0.0192735359526\n",
      "3  =  156.0 / 4280.0  =  0.0364485981308\n",
      "8  =  1501.0 / 14612.0  =  0.102723788667\n",
      "14  =  1113.0 / 6232.0  =  0.178594351733\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1166.0 / 3243.0  =  0.359543632439\n",
      "2  =  715.0 / 1918.0  =  0.372784150156\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0395729067367\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.129626211133\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  25.0 / 1349.0  =  0.0185322461082\n",
      "3  =  154.0 / 4280.0  =  0.0359813084112\n",
      "8  =  1492.0 / 14612.0  =  0.102107856556\n",
      "14  =  1121.0 / 6232.0  =  0.17987804878\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1170.0 / 3243.0  =  0.360777058279\n",
      "2  =  716.0 / 1918.0  =  0.37330552659\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratnaparkhi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0482208012741\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.132987339159\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  22.0 / 1624.0  =  0.0135467980296\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "5  =  97.0 / 5071.0  =  0.0191283770459\n",
      "9  =  46.0 / 1349.0  =  0.0340993328391\n",
      "3  =  164.0 / 4280.0  =  0.0383177570093\n",
      "8  =  1514.0 / 14612.0  =  0.103613468382\n",
      "14  =  1026.0 / 6232.0  =  0.164634146341\n",
      "10  =  437.0 / 1567.0  =  0.278876834716\n",
      "6  =  1243.0 / 3243.0  =  0.383287079864\n",
      "2  =  751.0 / 1918.0  =  0.391553701773\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.041023989362\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.130220510074\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "7  =  8.0 / 470.0  =  0.0170212765957\n",
      "9  =  28.0 / 1349.0  =  0.0207561156412\n",
      "3  =  157.0 / 4280.0  =  0.0366822429907\n",
      "8  =  1529.0 / 14612.0  =  0.1046400219\n",
      "14  =  1088.0 / 6232.0  =  0.17458279846\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  423.0 / 1567.0  =  0.269942565412\n",
      "6  =  1180.0 / 3243.0  =  0.36386062288\n",
      "2  =  713.0 / 1918.0  =  0.371741397289\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0398246270936\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.129787373284\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  76.0 / 5071.0  =  0.0149871820154\n",
      "9  =  27.0 / 1349.0  =  0.0200148257969\n",
      "3  =  156.0 / 4280.0  =  0.0364485981308\n",
      "8  =  1517.0 / 14612.0  =  0.103818779086\n",
      "14  =  1106.0 / 6232.0  =  0.177471116816\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1169.0 / 3243.0  =  0.360468701819\n",
      "2  =  713.0 / 1918.0  =  0.371741397289\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0397385342406\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.129435451239\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  26.0 / 1349.0  =  0.0192735359526\n",
      "3  =  156.0 / 4280.0  =  0.0364485981308\n",
      "8  =  1501.0 / 14612.0  =  0.102723788667\n",
      "14  =  1113.0 / 6232.0  =  0.178594351733\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  420.0 / 1567.0  =  0.268028079132\n",
      "6  =  1166.0 / 3243.0  =  0.359543632439\n",
      "2  =  715.0 / 1918.0  =  0.372784150156\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "4\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0395729067367\n",
      "Calculating test loss...\n",
      "Test Loss:\n",
      "0.129626211133\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  18.0 / 1624.0  =  0.0110837438424\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "5  =  77.0 / 5071.0  =  0.0151843817787\n",
      "9  =  25.0 / 1349.0  =  0.0185322461082\n",
      "3  =  154.0 / 4280.0  =  0.0359813084112\n",
      "8  =  1492.0 / 14612.0  =  0.102107856556\n",
      "14  =  1121.0 / 6232.0  =  0.17987804878\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  422.0 / 1567.0  =  0.269304403318\n",
      "6  =  1170.0 / 3243.0  =  0.360777058279\n",
      "2  =  716.0 / 1918.0  =  0.37330552659\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    sequenceLabeler.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
