{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from vowpalwabbit import pyvw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = {}\n",
    "tag['CC'] = 1\n",
    "tag['CD'] = 2\n",
    "tag['DT'] = 3\n",
    "tag['EX'] = 3\n",
    "tag['FW'] = 4\n",
    "tag['IN'] = 5\n",
    "tag['JJ'] = 6\n",
    "tag['JJR'] = 6\n",
    "tag['JJS'] = 6\n",
    "tag['MD'] = 7\n",
    "tag['NN'] = 8\n",
    "tag['NNP'] = 8\n",
    "tag['NNPS'] = 8\n",
    "tag['NNS'] = 8\n",
    "tag['PDT'] = 3\n",
    "tag['POS'] = 11\n",
    "tag['PRP'] = 9\n",
    "tag['PRP$'] = 9\n",
    "tag['RB'] = 10\n",
    "tag['RBR'] = 10\n",
    "tag['RBS'] = 10\n",
    "tag['RP'] = 11\n",
    "tag['SYM'] = 12\n",
    "tag['TO'] = 11\n",
    "tag['UH'] = 13\n",
    "tag['VB'] = 14\n",
    "tag['VBD'] = 14\n",
    "tag['VBG'] = 14\n",
    "tag['VBN'] = 14\n",
    "tag['VBP'] = 14\n",
    "tag['VBZ'] = 14\n",
    "tag['WDT'] = 3\n",
    "tag['WP'] = 9\n",
    "tag['WP$'] = 9\n",
    "tag['WRB'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = ''\n",
    "punc = ['#', '$',\"''\",'(',')',',','.',':',\"``\"]\n",
    "sentence = []\n",
    "sentences = []\n",
    "pos_tags = set([])\n",
    "file = open('train.txt', 'r') \n",
    "for line in file:\n",
    "    if line == '\\n': \n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    parts = line.split()\n",
    "    if parts[1] in punc:\n",
    "        continue\n",
    "    pos_tags.add(parts[1])\n",
    "    tup = (tag[parts[1]],parts[0])\n",
    "    sentence.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_test = []\n",
    "sentences_test = []\n",
    "pos_tags_test = set([])\n",
    "file = open('test.txt', 'r') \n",
    "for line in file:\n",
    "    if line == '\\n': \n",
    "        sentences_test.append(sentence_test)\n",
    "        sentence_test = []\n",
    "        continue\n",
    "    parts = line.split()\n",
    "    if parts[1] in punc:\n",
    "        continue\n",
    "    pos_tags_test.add(parts[1])\n",
    "    tup = (tag[parts[1]],parts[0])\n",
    "    sentence_test.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        # you must must must initialize the parent class\n",
    "        # this will automatically store self.sch <- sch, self.vw <- vw\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        \n",
    "        # set whatever options you want\n",
    "        sch.set_options( sch.AUTO_HAMMING_LOSS | sch.AUTO_CONDITION_FEATURES )\n",
    "\n",
    "    def _run(self, sentence):   # it's called _run to remind you that you shouldn't call it directly!\n",
    "        output = []\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            # use \"with...as...\" to guarantee that the example is finished properly\n",
    "            with self.vw.example({'w': [word]}) as ex:\n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'), (n-1, 'q')])\n",
    "                output.append(pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler2(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_HAMMING_LOSS)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        #loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            prevPred = output[n-1] if n > 0 else '<s>'\n",
    "            prev_n_2 = output[n-2] if n > 1 else '<s>'\n",
    "            posnew, prevWord = sentence[n-1] if n> 0 else ('<s>','<s>')\n",
    "            with self.vw.example({'w': [word],'p': [prevPred], 'r':[prevWord]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n,'r')])\n",
    "                output.append(pred)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "#sequenceLabeler2 = vw.init_search_task(SequenceLabeler2)\n",
    "#sequenceLabeler2.learn(my_dataset)\n",
    "#print(sequenceLabeler2.predict( [(0,w) for w in \"the sandwich ate a monster\".split()] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt = {}\n",
    "\n",
    "wt[1] = 1.0 \n",
    "wt[2] = 1.0\n",
    "wt[3] = 1.0\n",
    "wt[4] = 1.0\n",
    "wt[5] = 1.0\n",
    "wt[6] = 1.1\n",
    "wt[7] = 1.0\n",
    "wt[8] = 1.0\n",
    "wt[9] = 1.0\n",
    "wt[10] = 1.1\n",
    "wt[11] = 1.0\n",
    "wt[12] = 1.0\n",
    "wt[13] = 1.0\n",
    "wt[14] = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler3(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            with self.vw.example({'w': [word]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n-1,'q')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss += wt_err[pos]            \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss():\n",
    "    print(\"Calculating loss...\")\n",
    "    loss_t=[]\n",
    "    s=0\n",
    "    for sen in sentences_test:\n",
    "        s+=1\n",
    "        if(s%1000==0):\n",
    "            print(s)\n",
    "        temp=[]\n",
    "        for w in sen:\n",
    "            temp.append((1,w[1]))\n",
    "        out = sequenceLabeler3.predict(temp)\n",
    "        #print(out)\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in out:        \n",
    "            if sen[c][0] in tag_count:\n",
    "                tag_count[sen[c][0]] += 1\n",
    "            else:\n",
    "                tag_count[sen[c][0]] = float(1)\n",
    "                tag_error[sen[c][0]] = float(0)\n",
    "\n",
    "            if i != sen[c][0]:\n",
    "                loss+=1\n",
    "                tag_error[sen[c][0]] += 1\n",
    "                #print (\"Predicted value at \",c,\" is \",i)\n",
    "                #print (sentences[0][c])\n",
    "            c+=1\n",
    "        loss_t.append(loss/float(c))\n",
    "\n",
    "\n",
    "    print (sum(loss_t) / float(len(loss_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def updateWeights():\n",
    "    print(\"Updating weights...\")\n",
    "    tag_loss = {}\n",
    "    for t in tag_count:\n",
    "        tag_loss[t] = tag_error[t]/tag_count[t]\n",
    "\n",
    "    sorted_loss = sorted(tag_loss.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    for tp in sorted_loss:\n",
    "            print( tp[0], \" = \", tag_error[tp[0]], \"/\", tag_count[tp[0]], \" = \", tp[1] )\n",
    "            wt_err[tp[0]]=tp[1]\n",
    "            \n",
    "    avg_err=sum(wt_err)/14.0\n",
    "    wt_err[:]=[1+(x - avg_err) for x in wt_err]\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = pyvw.vw(\"--search 14 --audit --quiet --search_task hook --ring_size 1024 -f pos_tagger.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequenceLabeler3 = vw.init_search_task(SequenceLabeler3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_err=[1]*15\n",
    "tag_count = {}\n",
    "tag_error = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "0.136344372717\n",
      "Updating weights...\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "11  =  21.0 / 1624.0  =  0.0129310344828\n",
      "5  =  94.0 / 5071.0  =  0.0185367777559\n",
      "7  =  9.0 / 470.0  =  0.0191489361702\n",
      "9  =  46.0 / 1349.0  =  0.0340993328391\n",
      "3  =  163.0 / 4280.0  =  0.0380841121495\n",
      "8  =  1377.0 / 14612.0  =  0.0942376129209\n",
      "14  =  1299.0 / 6232.0  =  0.208440308087\n",
      "10  =  444.0 / 1567.0  =  0.283343969368\n",
      "6  =  1242.0 / 3243.0  =  0.382978723404\n",
      "2  =  755.0 / 1918.0  =  0.393639207508\n",
      "4  =  3.0 / 4.0  =  0.75\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "1\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "0.138028463875\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  70.0 / 5071.0  =  0.0138039834352\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  172.0 / 4280.0  =  0.0401869158879\n",
      "8  =  1562.0 / 14612.0  =  0.106898439639\n",
      "14  =  1432.0 / 6232.0  =  0.229781771502\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  424.0 / 1567.0  =  0.270580727505\n",
      "6  =  1140.0 / 3243.0  =  0.351526364477\n",
      "2  =  706.0 / 1918.0  =  0.368091762252\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "2\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "0.138267151021\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  71.0 / 5071.0  =  0.0140011831986\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  170.0 / 4280.0  =  0.0397196261682\n",
      "8  =  1565.0 / 14612.0  =  0.107103750342\n",
      "14  =  1446.0 / 6232.0  =  0.232028241335\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  423.0 / 1567.0  =  0.269942565412\n",
      "6  =  1142.0 / 3243.0  =  0.352143077397\n",
      "2  =  706.0 / 1918.0  =  0.368091762252\n",
      "13  =  2.0 / 2.0  =  1.0\n",
      "3\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "0.13869307686\n",
      "Updating weights...\n",
      "11  =  12.0 / 1624.0  =  0.00738916256158\n",
      "1  =  11.0 / 1214.0  =  0.00906095551895\n",
      "5  =  72.0 / 5071.0  =  0.0141983829619\n",
      "7  =  7.0 / 470.0  =  0.0148936170213\n",
      "9  =  30.0 / 1349.0  =  0.0222386953299\n",
      "3  =  170.0 / 4280.0  =  0.0397196261682\n",
      "8  =  1574.0 / 14612.0  =  0.107719682453\n",
      "14  =  1453.0 / 6232.0  =  0.233151476252\n",
      "4  =  1.0 / 4.0  =  0.25\n",
      "10  =  425.0 / 1567.0  =  0.271218889598\n",
      "6  =  1143.0 / 3243.0  =  0.352451433858\n",
      "2  =  706.0 / 1918.0  =  0.368091762252\n",
      "13  =  2.0 / 2.0  =  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print (i)\n",
    "    sequenceLabeler3.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    calculate_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=[]\n",
    "for w in sentences[0]:\n",
    "    temp.append((0,w[1]))\n",
    "print (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = sequenceLabeler2.predict(temp)\n",
    "print(out)\n",
    "loss=0\n",
    "c=0\n",
    "for i in out:\n",
    "    if i != sentences[0][c][0]:\n",
    "        loss+=1\n",
    "        print (\"Predicted value at \",c,\" is \",i)\n",
    "        print (sentences[0][c])\n",
    "    c+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
