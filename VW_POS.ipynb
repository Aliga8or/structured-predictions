{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from vowpalwabbit import pyvw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = {}\n",
    "tag['CC'] = 1\n",
    "tag['CD'] = 2\n",
    "tag['DT'] = 3\n",
    "tag['EX'] = 3\n",
    "tag['FW'] = 4\n",
    "tag['IN'] = 5\n",
    "tag['JJ'] = 6\n",
    "tag['JJR'] = 6\n",
    "tag['JJS'] = 6\n",
    "tag['MD'] = 7\n",
    "tag['NN'] = 8\n",
    "tag['NNP'] = 8\n",
    "tag['NNPS'] = 8\n",
    "tag['NNS'] = 8\n",
    "tag['PDT'] = 3\n",
    "tag['POS'] = 11\n",
    "tag['PRP'] = 9\n",
    "tag['PRP$'] = 9\n",
    "tag['RB'] = 10\n",
    "tag['RBR'] = 10\n",
    "tag['RBS'] = 10\n",
    "tag['RP'] = 11\n",
    "tag['SYM'] = 12\n",
    "tag['TO'] = 11\n",
    "tag['UH'] = 13\n",
    "tag['VB'] = 14\n",
    "tag['VBD'] = 14\n",
    "tag['VBG'] = 14\n",
    "tag['VBN'] = 14\n",
    "tag['VBP'] = 14\n",
    "tag['VBZ'] = 14\n",
    "tag['WDT'] = 3\n",
    "tag['WP'] = 9\n",
    "tag['WP$'] = 9\n",
    "tag['WRB'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = ''\n",
    "punc = ['#', '$',\"''\",'(',')',',','.',':',\"``\"]\n",
    "sentence = []\n",
    "sentences = []\n",
    "pos_tags = set([])\n",
    "file = open('train.txt', 'r') \n",
    "for line in file:\n",
    "    if line == '\\n': \n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    parts = line.split()\n",
    "    if parts[1] in punc:\n",
    "        continue\n",
    "    pos_tags.add(parts[1])\n",
    "    tup = (tag[parts[1]],parts[0])\n",
    "    sentence.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_test = []\n",
    "sentences_test = []\n",
    "pos_tags_test = set([])\n",
    "file = open('test.txt', 'r') \n",
    "for line in file:\n",
    "    if line == '\\n': \n",
    "        sentences_test.append(sentence_test)\n",
    "        sentence_test = []\n",
    "        continue\n",
    "    parts = line.split()\n",
    "    if parts[1] in punc:\n",
    "        continue\n",
    "    pos_tags_test.add(parts[1])\n",
    "    tup = (tag[parts[1]],parts[0])\n",
    "    sentence_test.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        # you must must must initialize the parent class\n",
    "        # this will automatically store self.sch <- sch, self.vw <- vw\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        \n",
    "        # set whatever options you want\n",
    "        sch.set_options( sch.AUTO_HAMMING_LOSS | sch.AUTO_CONDITION_FEATURES )\n",
    "\n",
    "    def _run(self, sentence):   # it's called _run to remind you that you shouldn't call it directly!\n",
    "        output = []\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            # use \"with...as...\" to guarantee that the example is finished properly\n",
    "            with self.vw.example({'w': [word]}) as ex:\n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'), (n-1, 'q')])\n",
    "                output.append(pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler2(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_HAMMING_LOSS)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        #loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            prevPred = output[n-1] if n > 0 else '<s>'\n",
    "            prev_n_2 = output[n-2] if n > 1 else '<s>'\n",
    "            posnew, prevWord = sentence[n-1] if n> 0 else ('<s>','<s>')\n",
    "            with self.vw.example({'w': [word],'p': [prevPred], 'r':[prevWord]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n,'r')])\n",
    "                output.append(pred)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "#sequenceLabeler2 = vw.init_search_task(SequenceLabeler2)\n",
    "#sequenceLabeler2.learn(my_dataset)\n",
    "#print(sequenceLabeler2.predict( [(0,w) for w in \"the sandwich ate a monster\".split()] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt = {}\n",
    "\n",
    "wt[1] = 1.0 \n",
    "wt[2] = 1.0\n",
    "wt[3] = 1.0\n",
    "wt[4] = 1.0\n",
    "wt[5] = 1.0\n",
    "wt[6] = 1.1\n",
    "wt[7] = 1.0\n",
    "wt[8] = 1.0\n",
    "wt[9] = 1.0\n",
    "wt[10] = 1.1\n",
    "wt[11] = 1.0\n",
    "wt[12] = 1.0\n",
    "wt[13] = 1.0\n",
    "wt[14] = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler3(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            with self.vw.example({'w': [word]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n-1,'q')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss += wt_err[pos]            \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_loss():\n",
    "    print(\"Calculating training loss...\")\n",
    "    loss_t=[]\n",
    "    s=0\n",
    "    for sen in sentences[:1000]:\n",
    "        s+=1\n",
    "        temp=[]\n",
    "        for w in sen:\n",
    "            temp.append((1,w[1]))\n",
    "        out = sequenceLabeler3.predict(temp)\n",
    "        #print(out)\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in out:        \n",
    "            if sen[c][0] in tag_count:\n",
    "                tag_count[sen[c][0]] += 1\n",
    "            else:\n",
    "                tag_count[sen[c][0]] = float(1)\n",
    "                tag_error[sen[c][0]] = float(0)\n",
    "\n",
    "            if i != sen[c][0]:\n",
    "                loss+=1\n",
    "                tag_error[sen[c][0]] += 1\n",
    "                #print (\"Predicted value at \",c,\" is \",i)\n",
    "                #print (sentences[0][c])\n",
    "            c+=1\n",
    "        loss_t.append(loss/float(c))\n",
    "\n",
    "    print (\"Training Loss:\")\n",
    "    print (sum(loss_t) / float(len(loss_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_loss():\n",
    "    print(\"Calculating loss...\")\n",
    "    loss_t=[]\n",
    "    s=0\n",
    "    for sen in sentences_test:\n",
    "        s+=1\n",
    "        if(s%1000==0):\n",
    "            print(s)\n",
    "        temp=[]\n",
    "        for w in sen:\n",
    "            temp.append((1,w[1]))\n",
    "        out = sequenceLabeler3.predict(temp)\n",
    "        #print(out)\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in out:        \n",
    "            if i != sen[c][0]:\n",
    "                loss+=1\n",
    "                #print (\"Predicted value at \",c,\" is \",i)\n",
    "                #print (sentences[0][c])\n",
    "            c+=1\n",
    "        loss_t.append(loss/float(c))\n",
    "\n",
    "    print (\"Test loss\")\n",
    "    print (sum(loss_t) / float(len(loss_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def updateWeights():\n",
    "    print(\"Updating weights...\")\n",
    "    tag_loss = {}\n",
    "    sum_err=0\n",
    "    for t in tag_count:\n",
    "        tag_loss[t] = tag_error[t]/tag_count[t]\n",
    "        sum_err+=tag_error[t]\n",
    "        \n",
    "    sorted_loss = sorted(tag_loss.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    for tp in sorted_loss:\n",
    "            print( tp[0], \" = \", tag_error[tp[0]], \"/\", tag_count[tp[0]], \" = \", tp[1] )\n",
    "            wt_err[tp[0]]=tp[1]*(tag_error[tp[0]]/sum_err)\n",
    "            \n",
    "    avg_err=sum(wt_err)/14.0\n",
    "    wt_err[:]=[1+(x - avg_err) for x in wt_err]\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = pyvw.vw(\"--search 14 --audit --quiet --search_task hook --ring_size 1024 -f pos_tagger.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequenceLabeler3 = vw.init_search_task(SequenceLabeler3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_err=[1]*15\n",
    "tag_count = {}\n",
    "tag_error = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0479161243961\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.136344372717\n",
      "Updating weights...\n",
      "1  =  0.0 / 575.0  =  0.0\n",
      "7  =  1.0 / 235.0  =  0.00425531914894\n",
      "5  =  27.0 / 2587.0  =  0.0104367993815\n",
      "11  =  9.0 / 806.0  =  0.0111662531017\n",
      "9  =  12.0 / 585.0  =  0.0205128205128\n",
      "3  =  67.0 / 2190.0  =  0.0305936073059\n",
      "8  =  260.0 / 7383.0  =  0.0352160368414\n",
      "14  =  224.0 / 3170.0  =  0.0706624605678\n",
      "6  =  176.0 / 1715.0  =  0.102623906706\n",
      "2  =  106.0 / 871.0  =  0.121699196326\n",
      "10  =  98.0 / 783.0  =  0.125159642401\n",
      "4  =  4.0 / 7.0  =  0.571428571429\n",
      "1\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0449351382448\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.136486973228\n",
      "Updating weights...\n",
      "1  =  0.0 / 575.0  =  0.0\n",
      "4  =  0.0 / 7.0  =  0.0\n",
      "7  =  0.0 / 235.0  =  0.0\n",
      "5  =  14.0 / 2587.0  =  0.00541167375338\n",
      "11  =  6.0 / 806.0  =  0.00744416873449\n",
      "9  =  8.0 / 585.0  =  0.0136752136752\n",
      "3  =  78.0 / 2190.0  =  0.0356164383562\n",
      "8  =  274.0 / 7383.0  =  0.037112284979\n",
      "2  =  63.0 / 871.0  =  0.0723306544202\n",
      "6  =  130.0 / 1715.0  =  0.0758017492711\n",
      "14  =  262.0 / 3170.0  =  0.0826498422713\n",
      "10  =  79.0 / 783.0  =  0.100893997446\n",
      "2\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0458724413709\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.138005137143\n",
      "Updating weights...\n",
      "1  =  0.0 / 575.0  =  0.0\n",
      "4  =  0.0 / 7.0  =  0.0\n",
      "7  =  0.0 / 235.0  =  0.0\n",
      "5  =  14.0 / 2587.0  =  0.00541167375338\n",
      "11  =  6.0 / 806.0  =  0.00744416873449\n",
      "9  =  8.0 / 585.0  =  0.0136752136752\n",
      "3  =  76.0 / 2190.0  =  0.034703196347\n",
      "8  =  306.0 / 7383.0  =  0.0414465664364\n",
      "2  =  60.0 / 871.0  =  0.0688863375431\n",
      "6  =  125.0 / 1715.0  =  0.0728862973761\n",
      "14  =  260.0 / 3170.0  =  0.0820189274448\n",
      "10  =  79.0 / 783.0  =  0.100893997446\n",
      "3\n",
      "Calculating training loss...\n",
      "Training Loss:\n",
      "0.0461785633157\n",
      "Calculating loss...\n",
      "1000\n",
      "2000\n",
      "Test loss\n",
      "0.138482103251\n",
      "Updating weights...\n",
      "1  =  0.0 / 575.0  =  0.0\n",
      "4  =  0.0 / 7.0  =  0.0\n",
      "7  =  0.0 / 235.0  =  0.0\n",
      "5  =  14.0 / 2587.0  =  0.00541167375338\n",
      "11  =  6.0 / 806.0  =  0.00744416873449\n",
      "9  =  7.0 / 585.0  =  0.0119658119658\n",
      "3  =  76.0 / 2190.0  =  0.034703196347\n",
      "8  =  308.0 / 7383.0  =  0.0417174590275\n",
      "2  =  58.0 / 871.0  =  0.0665901262916\n",
      "6  =  123.0 / 1715.0  =  0.0717201166181\n",
      "14  =  271.0 / 3170.0  =  0.0854889589905\n",
      "10  =  78.0 / 783.0  =  0.0996168582375\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print (i)\n",
    "    sequenceLabeler3.learn(sentences[:1000])\n",
    "    tag_count = {}\n",
    "    tag_error = {}\n",
    "    train_loss()\n",
    "    test_loss()\n",
    "    updateWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceLabeler4(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        sch.set_options(sch.AUTO_CONDITION_FEATURES)\n",
    "\n",
    "    def _run(self, sentence):\n",
    "        output = []\n",
    "        loss = 0.\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            with self.vw.example({'w': [word]}) as ex: \n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'),(n-1,'q')])\n",
    "                output.append(pred)\n",
    "                if pred != pos:\n",
    "                    loss += wt_err[pos]            \n",
    "        self.sch.loss(loss)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = sequenceLabeler2.predict(temp)\n",
    "print(out)\n",
    "loss=0\n",
    "c=0\n",
    "for i in out:\n",
    "    if i != sentences[0][c][0]:\n",
    "        loss+=1\n",
    "        print (\"Predicted value at \",c,\" is \",i)\n",
    "        print (sentences[0][c])\n",
    "    c+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
